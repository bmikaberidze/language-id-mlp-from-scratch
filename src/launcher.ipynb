{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636f8db1-7402-4f0a-93f0-b5fe442c6b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from language_detector import LanguageDetector\n",
    "model = LanguageDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "543b5b85-d95d-4bde-9772-502ba8988e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b2ed7-aab6-43a1-aeaa-e80eb16f84b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique features:  669\n",
      "Numbers of training, validation and test sentences:  210000 60000 30000\n",
      "1. Loss: 1.7879691460051266\n",
      "2. Loss: 1.7891628573645502\n",
      "3. Loss: 1.7899739855479333\n",
      "4. Loss: 1.792242678072708\n",
      "5. Loss: 1.7874926705712895\n",
      "6. Loss: 1.7931469032118759\n",
      "7. Loss: 1.7970558802021301\n",
      "8. Loss: 1.7872111471042962\n",
      "9. Loss: 1.7896084111390411\n",
      "10. Loss: 1.7883393739976716\n",
      "11. Loss: 1.7868791151865495\n",
      "12. Loss: 1.7879038667184486\n",
      "13. Loss: 1.7872655709241505\n",
      "14. Loss: 1.789700981071467\n",
      "15. Loss: 1.7884773046196645\n",
      "16. Loss: 1.783243051197705\n",
      "17. Loss: 1.786341434769009\n",
      "18. Loss: 1.7831285512893955\n",
      "19. Loss: 1.787986675902095\n",
      "20. Loss: 1.7837505393199522\n",
      "21. Loss: 1.7817757322739272\n",
      "22. Loss: 1.7842206392744626\n",
      "23. Loss: 1.77660640453809\n",
      "24. Loss: 1.786421509565972\n",
      "25. Loss: 1.7790869645449934\n",
      "26. Loss: 1.7793840722791512\n",
      "27. Loss: 1.7779748102374524\n",
      "28. Loss: 1.7795194299603545\n",
      "29. Loss: 1.7827055302932655\n",
      "30. Loss: 1.784347162297554\n",
      "31. Loss: 1.778628914844267\n",
      "32. Loss: 1.7790618199346897\n",
      "33. Loss: 1.7764011376473783\n",
      "34. Loss: 1.7771687951323474\n",
      "35. Loss: 1.7723154703108088\n",
      "36. Loss: 1.774329292731956\n",
      "37. Loss: 1.7731162712023163\n",
      "38. Loss: 1.7741850204962963\n",
      "39. Loss: 1.7728304805674457\n",
      "40. Loss: 1.7711087358825932\n",
      "41. Loss: 1.7688227296501635\n",
      "42. Loss: 1.769844393736335\n",
      "43. Loss: 1.7757894873575564\n",
      "44. Loss: 1.7698714244898444\n",
      "45. Loss: 1.7730856662556511\n",
      "46. Loss: 1.7686845065183916\n",
      "47. Loss: 1.7615869737641616\n",
      "48. Loss: 1.7703242934506331\n",
      "49. Loss: 1.7685836165559397\n",
      "50. Loss: 1.7693021137829086\n",
      "51. Loss: 1.7610543301378891\n",
      "52. Loss: 1.754039391412194\n",
      "53. Loss: 1.7586218637626092\n",
      "54. Loss: 1.7602732217241863\n",
      "55. Loss: 1.7639453031636239\n",
      "56. Loss: 1.7587783787824314\n",
      "57. Loss: 1.7590564844977272\n",
      "58. Loss: 1.7627195509883467\n",
      "59. Loss: 1.7640841059517127\n",
      "60. Loss: 1.7583739342105704\n",
      "61. Loss: 1.7534396144996267\n",
      "62. Loss: 1.7627663433331184\n",
      "63. Loss: 1.7517825103635787\n",
      "64. Loss: 1.7592319615933798\n",
      "65. Loss: 1.7528838025869502\n",
      "66. Loss: 1.7478195211464977\n",
      "67. Loss: 1.7522225536393656\n",
      "68. Loss: 1.746598998120661\n",
      "69. Loss: 1.7580047644665189\n",
      "70. Loss: 1.7533953803284978\n",
      "71. Loss: 1.751064170150768\n",
      "72. Loss: 1.7500854194937245\n",
      "73. Loss: 1.747025964916868\n",
      "74. Loss: 1.7463744688898657\n",
      "75. Loss: 1.7470375163777836\n",
      "76. Loss: 1.7454748269101545\n",
      "77. Loss: 1.739114552966961\n",
      "78. Loss: 1.745221181102854\n",
      "79. Loss: 1.7402850507285834\n",
      "80. Loss: 1.738469716215168\n",
      "81. Loss: 1.7459235942213522\n",
      "82. Loss: 1.7381979086100499\n",
      "83. Loss: 1.7384195578081394\n",
      "84. Loss: 1.7377573659695613\n",
      "85. Loss: 1.7331655406530049\n",
      "86. Loss: 1.7269129374440844\n",
      "87. Loss: 1.7316637918188307\n",
      "88. Loss: 1.726464042941643\n",
      "89. Loss: 1.7210414641673373\n",
      "90. Loss: 1.7442520808844415\n",
      "91. Loss: 1.7162068357871154\n",
      "92. Loss: 1.7279811321238545\n",
      "93. Loss: 1.7200112575668283\n",
      "94. Loss: 1.719473061298078\n",
      "95. Loss: 1.7261035750805434\n",
      "96. Loss: 1.7135074619771533\n",
      "97. Loss: 1.7068270476856595\n",
      "98. Loss: 1.7175520797329633\n",
      "99. Loss: 1.7084682447587682\n",
      "100. Loss: 1.704347300583743\n",
      "101. Loss: 1.7239235659215248\n",
      "102. Loss: 1.7113105228472387\n",
      "103. Loss: 1.6950662522024444\n",
      "104. Loss: 1.706664521473609\n",
      "105. Loss: 1.710993579741782\n",
      "106. Loss: 1.697492525280426\n",
      "107. Loss: 1.7003950835559427\n",
      "108. Loss: 1.6908237555574699\n",
      "109. Loss: 1.6855710376726167\n",
      "110. Loss: 1.6907940240930373\n",
      "111. Loss: 1.6935011835203317\n",
      "112. Loss: 1.6766387100794233\n",
      "113. Loss: 1.6908940992941865\n",
      "114. Loss: 1.6891930546861775\n",
      "115. Loss: 1.6694214858363237\n",
      "116. Loss: 1.6729095019129816\n",
      "117. Loss: 1.6788230229644454\n",
      "118. Loss: 1.668669303759448\n",
      "119. Loss: 1.6730908176850494\n",
      "120. Loss: 1.66208202305983\n",
      "121. Loss: 1.664760939189248\n",
      "122. Loss: 1.6454889227707585\n",
      "123. Loss: 1.6637968569136083\n",
      "124. Loss: 1.6388168572048074\n",
      "125. Loss: 1.6570814475338744\n",
      "126. Loss: 1.6483229623960989\n",
      "127. Loss: 1.6626919394994548\n",
      "128. Loss: 1.6440458707402816\n",
      "129. Loss: 1.636141300908381\n",
      "130. Loss: 1.640803695473319\n",
      "131. Loss: 1.6252740036931954\n",
      "132. Loss: 1.631746190861314\n",
      "133. Loss: 1.6199171662470326\n",
      "134. Loss: 1.6162247893862445\n",
      "135. Loss: 1.6085889384938679\n",
      "136. Loss: 1.604297186901057\n",
      "137. Loss: 1.6238737836019086\n",
      "138. Loss: 1.61843746031175\n",
      "139. Loss: 1.6095745838066575\n",
      "140. Loss: 1.6084514258734608\n",
      "141. Loss: 1.5896546379957155\n",
      "142. Loss: 1.57521521823177\n",
      "143. Loss: 1.5886223054242432\n",
      "144. Loss: 1.581263740649217\n",
      "145. Loss: 1.5612390672906247\n",
      "146. Loss: 1.5754388738389427\n",
      "147. Loss: 1.5605452917859322\n",
      "148. Loss: 1.5659789046285946\n",
      "149. Loss: 1.5638330885499558\n",
      "150. Loss: 1.5551963477895918\n",
      "151. Loss: 1.5358529216646701\n",
      "152. Loss: 1.528578573382766\n",
      "153. Loss: 1.5494583503922064\n",
      "154. Loss: 1.4928549317879856\n",
      "155. Loss: 1.5474571274293418\n",
      "156. Loss: 1.526740643092431\n",
      "157. Loss: 1.5289238643624938\n",
      "158. Loss: 1.4650202165277477\n",
      "159. Loss: 1.4772621917129616\n",
      "160. Loss: 1.4978676225963639\n",
      "161. Loss: 1.479107892269528\n",
      "162. Loss: 1.5085361791399767\n",
      "163. Loss: 1.4425280245997079\n",
      "164. Loss: 1.4643214179751305\n",
      "165. Loss: 1.4093092575919226\n",
      "166. Loss: 1.4244662225408342\n",
      "167. Loss: 1.4382099742450405\n",
      "168. Loss: 1.4717254443496202\n",
      "169. Loss: 1.4025664473763912\n",
      "170. Loss: 1.3698242509145997\n",
      "171. Loss: 1.3679023257038543\n",
      "172. Loss: 1.400719068842825\n",
      "173. Loss: 1.3482369678561852\n",
      "174. Loss: 1.3816123919051981\n",
      "175. Loss: 1.3319126775441419\n",
      "176. Loss: 1.3322499761637538\n",
      "177. Loss: 1.3509444190943134\n",
      "178. Loss: 1.3437454040172605\n",
      "179. Loss: 1.3190571776406315\n",
      "180. Loss: 1.2566798618093902\n",
      "181. Loss: 1.3401364140509344\n",
      "182. Loss: 1.2747177431778143\n",
      "183. Loss: 1.2706222776536351\n",
      "184. Loss: 1.2355941233179069\n",
      "185. Loss: 1.2181440106685986\n",
      "186. Loss: 1.2336917482928185\n",
      "187. Loss: 1.1910255953906113\n",
      "188. Loss: 1.192460568398237\n",
      "189. Loss: 1.185619426993312\n",
      "190. Loss: 1.1318763658254956\n",
      "191. Loss: 1.2101185512020427\n",
      "192. Loss: 1.126217435823962\n",
      "193. Loss: 1.1749004910458671\n",
      "194. Loss: 1.1566409211547104\n",
      "195. Loss: 1.1260747267204267\n",
      "196. Loss: 1.0782546121110061\n",
      "197. Loss: 1.0746066432678305\n",
      "198. Loss: 1.1122558498778454\n",
      "199. Loss: 1.1477503861897609\n",
      "200. Loss: 1.0657145975672593\n",
      "201. Loss: 1.0889250685434737\n",
      "202. Loss: 1.0030388600677766\n",
      "203. Loss: 0.9512319218601273\n",
      "204. Loss: 0.9869639747934151\n",
      "205. Loss: 1.004394872212351\n",
      "206. Loss: 0.8952600551821233\n",
      "207. Loss: 0.9632084367992902\n",
      "208. Loss: 0.9260230074009449\n",
      "209. Loss: 0.9400057797107375\n",
      "210. Loss: 0.9568086598999845\n",
      "211. Loss: 0.9752301515267585\n",
      "212. Loss: 0.902072954589705\n",
      "213. Loss: 0.8745137023581978\n",
      "214. Loss: 0.8584230474749923\n",
      "215. Loss: 0.9696282524040999\n",
      "216. Loss: 0.8338649268082408\n",
      "217. Loss: 0.7988186527090368\n",
      "218. Loss: 0.7932801905736917\n",
      "219. Loss: 0.9037333079243379\n",
      "220. Loss: 0.8049609265072122\n",
      "221. Loss: 0.7937439751725925\n",
      "222. Loss: 0.893681711717378\n",
      "223. Loss: 0.8708811942017792\n",
      "224. Loss: 0.7892905047175108\n",
      "225. Loss: 0.8046608855646391\n",
      "226. Loss: 0.8167534402378333\n",
      "227. Loss: 0.7905172465623468\n",
      "228. Loss: 0.7929235548137596\n",
      "229. Loss: 0.7383915240936516\n",
      "230. Loss: 0.7894880417373946\n",
      "231. Loss: 0.8377348663932395\n",
      "232. Loss: 0.7306321616445303\n",
      "233. Loss: 0.7076152485513244\n",
      "234. Loss: 0.724394998932365\n",
      "235. Loss: 0.6797680805627183\n",
      "236. Loss: 0.7600276290185684\n",
      "237. Loss: 0.674731469088192\n",
      "238. Loss: 0.6972731765804002\n",
      "239. Loss: 0.7084537714176875\n",
      "240. Loss: 0.5808206897964193\n",
      "241. Loss: 0.6542643523659027\n",
      "242. Loss: 0.6627047501312578\n",
      "243. Loss: 0.636973549735502\n",
      "244. Loss: 0.6991114320079564\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e289ac2-881d-48b0-a5ad-744e59af33c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8648a013-b483-4300-94a1-56bb69abd102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.tunning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4073cca0-9af5-4c4d-82a3-8da5262322c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
